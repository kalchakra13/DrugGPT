LLAMA_CONFIGS:
  model_name: 'meta-llama/Llama-2-7b-chat-hf'
  quantization_config:
    load_in_4bit: true
    bnb_4bit_quant_type: 'nf4'
    bnb_4bit_compute_dtype: 'float16'
    bnb_4bit_use_double_quant: false
  device_map: {'': 0}
  use_auth_token: true
  max_length: 500

SOFT_PROMPT_CONFIGS:
  epochs: 10
  learning_rate: 0.001
  optimizer: 'Adam'
  weight_decay: 0.0
  lr_scheduler_type: 'linear'
  warmup_ratio: 0.1
  gradient_clip: null
  logging_interval: 100
  forgiveness: 2

GCN_CONFIGS:
    'input_dim': 384,
    'hidden_dim': 128,
    'output_dim': 3404,
    'learning_rate': 0.001,
    'weight_decay': 0.01,
    'epochs': 10,
    'warmup_ratio': 0.1,

DATA_LOADER_CONFIGS:
  batch_size: 1
  max_length: 512
  val_split: 0.2
  shuffle: true
  random_state: 42
